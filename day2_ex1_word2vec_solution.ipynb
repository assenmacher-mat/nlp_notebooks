{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Day 2 - Exercise 1 - Word2Vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Necessary imports\n",
    "\n",
    "In order to handle the data properly we have to import the data and the modules we need:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# modules\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import nltk\n",
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First of all, you need to download the data set \"trump.csv\" from the GitHub repository https://github.com/assenmacher-mat/nlp_notebooks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__If you are running this notebook on colab ( https://colab.research.google.com/ ), you also need to run the next chunk in order to upload the data to colab.  \n",
    "Choose it in the upload window and in it will be available on colab from now on.__  \n",
    "(If you are running this notebook locally on your machine, you can skip the execution of this chunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "uploaded = files.upload()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import the data set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__If you are running this notebook locally on your machine, you might need to adjust the path (depending on where you've saved the data).__  \n",
    "(If you are running this notebook on colab, you can can leave the path unchanged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_data = pd.read_csv(\"trump.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Next, just have a look at the data set in order to see what's inside"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>text</th>\n",
       "      <th>created_at</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>favorite_count</th>\n",
       "      <th>is_retweet</th>\n",
       "      <th>id_str</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>At the request of @SenThomTillis I have declar...</td>\n",
       "      <td>10-04-2019 21:59:44</td>\n",
       "      <td>8562</td>\n",
       "      <td>36356</td>\n",
       "      <td>False</td>\n",
       "      <td>1180241114403610626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>Under my Administration Medicare Advantage pre...</td>\n",
       "      <td>10-04-2019 21:57:17</td>\n",
       "      <td>15248</td>\n",
       "      <td>54729</td>\n",
       "      <td>False</td>\n",
       "      <td>1180240498478534658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>WOW this is big stuff! https://t.co/H12yxMfua3</td>\n",
       "      <td>10-04-2019 19:46:59</td>\n",
       "      <td>15655</td>\n",
       "      <td>50526</td>\n",
       "      <td>False</td>\n",
       "      <td>1180207709985165313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>“I think it’s outrages that a Whistleblower is...</td>\n",
       "      <td>10-04-2019 14:12:23</td>\n",
       "      <td>19441</td>\n",
       "      <td>73966</td>\n",
       "      <td>False</td>\n",
       "      <td>1180123504924151809</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               source                                               text  \\\n",
       "0  Twitter for iPhone  At the request of @SenThomTillis I have declar...   \n",
       "1  Twitter for iPhone  Under my Administration Medicare Advantage pre...   \n",
       "2  Twitter for iPhone     WOW this is big stuff! https://t.co/H12yxMfua3   \n",
       "3  Twitter for iPhone  “I think it’s outrages that a Whistleblower is...   \n",
       "\n",
       "            created_at  retweet_count  favorite_count  is_retweet  \\\n",
       "0  10-04-2019 21:59:44           8562           36356       False   \n",
       "1  10-04-2019 21:57:17          15248           54729       False   \n",
       "2  10-04-2019 19:46:59          15655           50526       False   \n",
       "3  10-04-2019 14:12:23          19441           73966       False   \n",
       "\n",
       "                id_str  \n",
       "0  1180241114403610626  \n",
       "1  1180240498478534658  \n",
       "2  1180207709985165313  \n",
       "3  1180123504924151809  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet_data.loc[:3,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract the tweets to a list of texts:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_raw = [tweet for tweet in list(tweet_data.text)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display one exemplary tweet:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Under my Administration Medicare Advantage premiums next year will be their lowest in the last 13 years. We are providing GREAT healthcare to our Seniors. We cannot let the radical socialists take that away through Medicare for All!\n"
     ]
    }
   ],
   "source": [
    "print(tweets_raw[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform the (most) basic preprocessing steps before we continue:\n",
    "    - everything to lowercase\n",
    "    - delete url adresses\n",
    "    - delete other unwanted tokens\n",
    "    - tokenizing\n",
    "Depite thorough preprocessing is _essential_ for a good model, we won't spend much time on it here,  \n",
    "as the main focus in this tutorial is on the modeling part."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = [doc.lower() for doc in tweets_raw]                                          # everything to lowercase"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print a list of unique tokens that are at the moment present in our corpus\n",
    "### Based on this, we can identify which tokens occur the we potentially want to exclude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['!', '#', '$', '%', '&', \"'\", \"''\", \"'case\", \"'collusion\", \"'could\", \"'crisis\", \"'forgotten\", \"'god\", \"'right\", \"'s\", \"'spying\", \"'ve\", '(', ')', '+', '-', '--', '.', '..', '...', '..again', '..all', '..also', '..amounts', '..are', '..between', '..breaking', '..but', '..call', '..came', '..chairman', '..comcast', '..congresswomen', '..deferral', '..despite', '..if', '..mexico', '..much', '..my', '..news', '..nice', '..not', '..now', '..on', '..other', '..saying', '..shouting', '..sorry', '..spread', '..thank', '..that', '..the', '..there', '..this', '..to', '..tv', '..united', '..was', '..we', '..who', '..why', '..willing', '..years', '.33000', '.a', '.about', '.adds', '.after', '.again', '.agricultural', '.alabama', '.alex', '.all', '.almost', '.also', '.alternative', '.amendment.', '.amounts', '.an', '.and', '.another', '.are', '.as', '.asking', '.at', '.average', '.back', '.bad', '.based', '.be', '.became', '.because', '.best', '.better', '.between']\n"
     ]
    }
   ],
   "source": [
    "print(sorted(set(nltk.word_tokenize(\" \".join(tweets))))[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = [re.sub(r\"https://.*|“|”|@\", \"\", doc) for doc in tweets]                      # url adresses\n",
    "tweets = [re.sub(r\"[\\)\\(\\.\\,;:!?\\+\\-\\_\\#\\'\\*\\§\\$\\%\\&]\", \"\", doc) for doc in tweets]    # other unwanted tokens\n",
    "tweets = [nltk.word_tokenize(doc) for doc in tweets]                                   # tokenization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# After all, we can finally start with the modeling part!  \n",
    "(If you want to have a look at the help page, just execute the following chunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(Word2Vec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First, we determine the number of CPUs that are available on our machine  \n",
    "(The more cores are available, the faster we can train our model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    }
   ],
   "source": [
    "import multiprocessing\n",
    "cpus = multiprocessing.cpu_count()\n",
    "print(cpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up the model parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_model = Word2Vec(sg = 0, cbow_mean = 1, size = 100, alpha = 0.025, min_alpha = 0.0001, \n",
    "                     window = 5, min_count = 5, sample = 0.001, negative = 5, workers = cpus - 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize the model with our twitter data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_model.build_vocab(sentences = tweets, update = False, progress_per = 10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train our model:  \n",
    "(Hint: If you want to compare the runtime of the model for different number of cores or epochs, just put \"%timeit\" in front of the command  \n",
    " in the next chunk. You will then get an evaluation of how long the process takes.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7089354, 10534100)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_model.train(sentences = tweets, total_examples = w2v_model.corpus_count, epochs = 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now: Explore your model!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('biarritz', 0.5301661491394043), ('g7', 0.46447229385375977), ('paying', 0.43259501457214355), ('200', 0.4279639720916748), ('france', 0.4116533696651459), ('countries', 0.40288442373275757), ('interest', 0.39133787155151367), ('warren', 0.37755119800567627), ('suggested', 0.372894823551178), ('eu', 0.37280911207199097)]\n",
      "[('hillary', 0.6644464731216431), ('crooked', 0.6265661716461182), ('dnc', 0.5168795585632324), ('foundation', 0.4984697103500366), ('deleted', 0.4910370111465454), ('antitrump', 0.4390960931777954), ('33000', 0.43572330474853516), ('russians', 0.4113352298736572), ('campaign', 0.3964681625366211), ('acid', 0.3951607644557953)]\n",
      "[('dems', 0.7258269786834717), ('democrat', 0.4641879200935364), ('they', 0.4560657739639282), ('we', 0.3688978850841522), ('losers', 0.3611629009246826), ('people', 0.325318306684494), ('others', 0.3235127925872803), ('fix', 0.3084690570831299), ('migrants', 0.3068027198314667), ('dnc', 0.2996412515640259)]\n",
      "[('illegals', 0.4281608760356903), ('trade', 0.4229581356048584), ('china', 0.40108489990234375), ('caravans', 0.3943471610546112), ('immigration', 0.35160642862319946), ('wall', 0.3324584364891052), ('security', 0.3320930600166321), ('unfair', 0.3287833333015442), ('usa', 0.3233283758163452), ('system', 0.31981199979782104)]\n",
      "[('trade', 0.4772854745388031), ('tariffs', 0.4109834134578705), ('mexico', 0.40108487010002136), ('eu', 0.3981078565120697), ('money', 0.38679996132850647), ('talks', 0.38402533531188965), ('economy', 0.37625056505203247), ('advantage', 0.37134912610054016), ('unfair', 0.3691174387931824), ('consumers', 0.35524338483810425)]\n",
      "[('china', 0.4600461721420288), ('unfair', 0.38645875453948975), ('usmca', 0.3679531514644623), ('deals', 0.34424248337745667), ('both', 0.33711302280426025), ('cost', 0.33454564213752747), ('nafta', 0.32797694206237793), ('scheduled', 0.32759007811546326), ('benefit', 0.31746381521224976), ('talks', 0.3152797818183899)]\n"
     ]
    }
   ],
   "source": [
    "print(w2v_model.wv.most_similar(positive = [\"germany\"]))\n",
    "print(w2v_model.wv.most_similar(positive = [\"clinton\"]))\n",
    "print(w2v_model.wv.most_similar(positive = [\"democrats\"]))\n",
    "print(w2v_model.wv.most_similar(positive = [\"mexico\"]))\n",
    "print(w2v_model.wv.most_similar(positive = [\"china\"]))\n",
    "print(w2v_model.wv.most_similar(positive = [\"mexico\", \"trade\"], negative = [\"wall\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explore the possibilities the model by e.g. switching from skip-gram to cbow, using averaging instead of concatenation, chosing a larger embedding size, more negative examples, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try using ``gensim.models.phrases`` in order to form bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.phrases import Phrases, Phraser\n",
    "\n",
    "phrases = Phrases(tweets, min_count=20, threshold=10)\n",
    "bigram = Phraser(phrases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[((b'\\xe2\\x80\\x99', b've'), 37.407930594794614),\n",
       " ((b'\\xe2\\x80\\x99', b't'), 50.150730122546605),\n",
       " ((b'\\xe2\\x80\\x99', b's'), 49.4195657370932),\n",
       " ((b'\\xe2\\x80\\x99', b're'), 40.11865020311306),\n",
       " ((b'\\xe2\\x80\\x99', b'm'), 30.050559826469744),\n",
       " ((b'\\xe2\\x80\\x99', b'll'), 24.282340912410536),\n",
       " ((b'york', b'times'), 395.1158645276292),\n",
       " ((b'years', b'ago'), 42.35973092799266),\n",
       " ((b'would', b'be'), 18.73117701107837),\n",
       " ((b'working', b'hard'), 67.47640791476408),\n",
       " ((b'won', b'\\xe2\\x80\\x99'), 16.404070305272896),\n",
       " ((b'witch', b'hunt'), 468.57365376056964),\n",
       " ((b'will', b'soon'), 18.06519967400163),\n",
       " ((b'will', b'never'), 10.333906593178899),\n",
       " ((b'will', b'be'), 22.72071968863337),\n",
       " ((b'white', b'house'), 405.0390956994731),\n",
       " ((b'we', b'need'), 13.451875227576162),\n",
       " ((b'we', b'are'), 12.779281466197354),\n",
       " ((b'wasn', b'\\xe2\\x80\\x99'), 17.087573234659263),\n",
       " ((b'washington', b'post'), 498.48575712143924),\n",
       " ((b'very', b'well'), 16.03628892232897),\n",
       " ((b'very', b'important'), 24.038235111854743),\n",
       " ((b'very', b'good'), 16.103810138844043),\n",
       " ((b've', b'got'), 29.954054054054055),\n",
       " ((b'united', b'states'), 231.3194278269655),\n",
       " ((b'united', b'kingdom'), 42.84112872052571),\n",
       " ((b'ukrainian', b'president'), 15.393055555555556),\n",
       " ((b'two', b'years'), 76.97785585880045),\n",
       " ((b'two', b'weeks'), 50.28584392014519),\n",
       " ((b'trying', b'to'), 15.04146139543721),\n",
       " ((b'trump', b'haters'), 25.768425947454077),\n",
       " ((b'trump', b'campaign'), 20.53421442687747),\n",
       " ((b'trump', b'administration'), 23.467673630717112),\n",
       " ((b'trade', b'deals'), 37.09170013386881),\n",
       " ((b'trade', b'deal'), 53.606982675226455),\n",
       " ((b'total', b'endorsement'), 182.52635046113306),\n",
       " ((b'this', b'morning'), 16.89584730776267),\n",
       " ((b'they', b'are'), 10.185487549640442),\n",
       " ((b'there', b'was'), 10.961208791208792),\n",
       " ((b'their', b'partner'), 33.83777732546306),\n",
       " ((b'thank', b'you'), 80.20902511707109),\n",
       " ((b'than', b'ever'), 16.217969562955258),\n",
       " ((b'talking', b'about'), 33.738203957382034),\n",
       " ((b'talk', b'about'), 36.14807566862361),\n",
       " ((b't', b'want'), 15.359664979513138),\n",
       " ((b't', b'know'), 16.54212024119883),\n",
       " ((b'supreme', b'court'), 731.4091614906831),\n",
       " ((b'stock', b'market'), 820.9629629629629),\n",
       " ((b'state', b'of'), 11.219246529858603),\n",
       " ((b'southern', b'border'), 154.13273584176775),\n",
       " ((b'south', b'korea'), 33.584848484848486),\n",
       " ((b'south', b'carolina'), 90.84426229508196),\n",
       " ((b'social', b'media'), 94.88869863013699),\n",
       " ((b'so', b'true'), 16.139843554963804),\n",
       " ((b'so', b'much'), 23.014997692662664),\n",
       " ((b'so', b'many'), 16.757965223026247),\n",
       " ((b'sleepy', b'joe'), 674.421906693712),\n",
       " ((b'should', b'never'), 17.393283113622093),\n",
       " ((b'should', b'be'), 12.020881855962005),\n",
       " ((b'secretary', b'of'), 10.604265608962649),\n",
       " ((b'second', b'amendment'), 249.99248120300754),\n",
       " ((b'sanctuary', b'cities'), 651.9411764705882),\n",
       " ((b'same', b'time'), 34.80841708542714),\n",
       " ((b'robert', b'mueller'), 189.2219512195122),\n",
       " ((b'right', b'now'), 32.13449993177787),\n",
       " ((b'republican', b'party'), 171.03395061728395),\n",
       " ((b'radical', b'left'), 433.5748882265276),\n",
       " ((b'quantitative', b'tightening'), 651.9411764705882),\n",
       " ((b'puerto', b'rico'), 1382.2335600907031),\n",
       " ((b'prime', b'minister'), 903.0592592592592),\n",
       " ((b'presidential', b'harassment'), 452.3673469387754),\n",
       " ((b'president', b'xi'), 59.37321428571429),\n",
       " ((b'president', b'trump'), 31.212005928853753),\n",
       " ((b'president', b'obama'), 19.791071428571428),\n",
       " ((b'pleased', b'to'), 11.477289021301003),\n",
       " ((b'people', b'who'), 13.913000190466297),\n",
       " ((b'part', b'of'), 13.01432597463598),\n",
       " ((b'oval', b'office'), 115.20790020790021),\n",
       " ((b'our', b'vets'), 14.947017570900123),\n",
       " ((b'our', b'southern'), 23.041249677400856),\n",
       " ((b'our', b'nation'), 22.7764077270859),\n",
       " ((b'our', b'farmers'), 10.31384500849173),\n",
       " ((b'our', b'country'), 45.48660496659307),\n",
       " ((b'other', b'side'), 34.291460396039604),\n",
       " ((b'other', b'countries'), 97.97560113154172),\n",
       " ((b'open', b'borders'), 480.39520652728197),\n",
       " ((b'obama', b'administration'), 41.885865457294024),\n",
       " ((b'number', b'one'), 53.02870813397129),\n",
       " ((b'north', b'korea'), 354.30169830169837),\n",
       " ((b'north', b'carolina'), 369.3667807602234),\n",
       " ((b'no', b'obstruction'), 67.53082437275985),\n",
       " ((b'no', b'longer'), 52.96535244922342),\n",
       " ((b'no', b'inflation'), 17.655117483074473),\n",
       " ((b'no', b'collusion'), 66.20669056152927),\n",
       " ((b'news', b'media'), 55.95197190951973),\n",
       " ((b'new', b'york'), 187.56244164332398),\n",
       " ((b'new', b'book'), 27.487599206349206),\n",
       " ((b'never', b'forget'), 13.044962335216573),\n",
       " ((b'never', b'been'), 11.068452890486789),\n",
       " ((b'national', b'security'), 26.287950664136623),\n",
       " ((b'national', b'emergency'), 106.29475703324809),\n",
       " ((b'nancy', b'pelosi'), 599.0810810810812),\n",
       " ((b'my', b'full'), 13.095828902280514),\n",
       " ((b'my', b'friend'), 15.03595170261837),\n",
       " ((b'my', b'administration'), 14.498953427524857),\n",
       " ((b'mueller', b'report'), 175.16235632183907),\n",
       " ((b'much', b'more'), 23.563563049853368),\n",
       " ((b'more', b'than'), 28.83194588969823),\n",
       " ((b'millions', b'of'), 13.01432597463598),\n",
       " ((b'michael', b'cohen'), 153.93055555555554),\n",
       " ((b'meeting', b'with'), 15.99863345908076),\n",
       " ((b'many', b'years'), 33.52727639407078),\n",
       " ((b'many', b'other'), 18.677901832736463),\n",
       " ((b'make', b'america'), 67.66178266178267),\n",
       " ((b'mainstream', b'media'), 113.8664383561644),\n",
       " ((b'made', b'up'), 36.00577128879376),\n",
       " ((b'low', b'ratings'), 27.005360623781677),\n",
       " ((b'lot', b'of'), 10.845271645529982),\n",
       " ((b'looking', b'forward'), 95.07475490196079),\n",
       " ((b'look', b'forward'), 188.68906810035844),\n",
       " ((b'look', b'at'), 10.682752859529623),\n",
       " ((b'left', b'democrats'), 24.7320447679209),\n",
       " ((b'law', b'enforcement'), 705.5150462962963),\n",
       " ((b'last', b'night'), 198.84278986319805),\n",
       " ((b'lamestream', b'media'), 112.46067985794012),\n",
       " ((b'kim', b'jong'), 828.8568376068376),\n",
       " ((b'keep', b'america'), 55.35964035964036),\n",
       " ((b'just', b'spoke'), 11.544791666666667),\n",
       " ((b'jong', b'un'), 1346.892361111111),\n",
       " ((b'joe', b'biden'), 403.58263305322123),\n",
       " ((b'jobs', b'jobs'), 81.97485207100593),\n",
       " ((b'jay', b'powell'), 304.478021978022),\n",
       " ((b'james', b'comey'), 429.5736434108527),\n",
       " ((b'it', b'was'), 11.34473399196957),\n",
       " ((b'is', b'doing'), 11.885509608785176),\n",
       " ((b'interest', b'rates'), 144.81271777003482),\n",
       " ((b'in', b'order'), 17.82979407979408),\n",
       " ((b'in', b'2020'), 12.480855855855856),\n",
       " ((b'immigration', b'laws'), 320.68865740740745),\n",
       " ((b'illegal', b'immigration'), 74.18340026773762),\n",
       " ((b'illegal', b'immigrants'), 235.64138908575478),\n",
       " ((b'i', b'am'), 44.70220044516813),\n",
       " ((b'human', b'trafficking'), 407.4632352941176),\n",
       " ((b'hillary', b'clinton'), 324.66389145852605),\n",
       " ((b'highly', b'respected'), 267.70531400966183),\n",
       " ((b'have', b'been'), 27.93466681884761),\n",
       " ((b'has', b'done'), 15.847572746121399),\n",
       " ((b'has', b'been'), 32.66132146413837),\n",
       " ((b'great', b'state'), 22.392914870689655),\n",
       " ((b'great', b'job'), 22.516437647754138),\n",
       " ((b'great', b'honor'), 19.426332131410255),\n",
       " ((b'great', b'again'), 18.445625783208023),\n",
       " ((b'got', b'caught'), 36.943333333333335),\n",
       " ((b'god', b'bless'), 907.0907738095239),\n",
       " ((b'forward', b'to'), 13.198882374496153),\n",
       " ((b'federal', b'reserve'), 593.8078836586299),\n",
       " ((b'far', b'too'), 29.35738503920322),\n",
       " ((b'far', b'more'), 10.34137563316449),\n",
       " ((b'far', b'better'), 10.5281656692315),\n",
       " ((b'fantastic', b'job'), 12.677876916037519),\n",
       " ((b'fake', b'news'), 133.24681753889675),\n",
       " ((b'failing', b'new'), 47.12159863945578),\n",
       " ((b'fact', b'that'), 17.275079493734022),\n",
       " ((b'even', b'though'), 96.87937062937063),\n",
       " ((b'enemy', b'of'), 10.011019980489214),\n",
       " ((b'elijah', b'cummings'), 659.702380952381),\n",
       " ((b'el', b'paso'), 1209.454365079365),\n",
       " ((b'drug', b'prices'), 162.5073313782991),\n",
       " ((b'donald', b'trump'), 60.42251601471992),\n",
       " ((b'don', b'\\xe2\\x80\\x99'), 45.250425417708804),\n",
       " ((b'doesn', b'\\xe2\\x80\\x99'), 42.108662613981764),\n",
       " ((b'do', b'nothing'), 17.34220028887819),\n",
       " ((b'didn', b'\\xe2\\x80\\x99'), 44.85487974098057),\n",
       " ((b'democrat', b'party'), 94.24319727891157),\n",
       " ((b'dan', b'bishop'), 820.962962962963),\n",
       " ((b'crooked', b'hillary'), 505.1858345021038),\n",
       " ((b'couldn', b'\\xe2\\x80\\x99'), 14.646491343993654),\n",
       " ((b'corrupt', b'news'), 10.45073078736445),\n",
       " ((b'corrupt', b'media'), 21.68884540117417),\n",
       " ((b'conversation', b'with'), 22.04256165473349),\n",
       " ((b'congress', b'must'), 12.39154740608229),\n",
       " ((b'congratulations', b'to'), 11.799416675745),\n",
       " ((b'committed', b'by'), 16.755190485789154),\n",
       " ((b'come', b'back'), 37.71438294010889),\n",
       " ((b'collusion', b'no'), 16.77236160892075),\n",
       " ((b'chairman', b'kim'), 236.8162393162393),\n",
       " ((b'by', b'far'), 10.154660900478277),\n",
       " ((b'by', b'crooked'), 11.890780344753594),\n",
       " ((b'border', b'security'), 98.98010216839924),\n",
       " ((b'border', b'patrol'), 120.6192003665941),\n",
       " ((b'billions', b'of'), 11.644396924674297),\n",
       " ((b'billion', b'dollars'), 287.5500370644922),\n",
       " ((b'better', b'than'), 35.957081942899514),\n",
       " ((b'being', b'built'), 59.90091280326687),\n",
       " ((b'be', b'interviewed'), 17.082305795314426),\n",
       " ((b'be', b'allowed'), 14.999097771495592),\n",
       " ((b'based', b'on'), 38.75174825174825),\n",
       " ((b'attorney', b'general'), 152.65840220385675),\n",
       " ((b'at', b'least'), 14.718459495351926),\n",
       " ((b'as', b'usual'), 14.90451855836471),\n",
       " ((b'as', b'possible'), 10.577400267226569),\n",
       " ((b'are', b'doing'), 11.172379032258064),\n",
       " ((b'approval', b'rating'), 833.3082706766917),\n",
       " ((b'announce', b'that'), 11.0048654552676),\n",
       " ((b'angry', b'democrats'), 17.937526974536038),\n",
       " ((b'an', b'outstanding'), 12.388777107086966),\n",
       " ((b'american', b'people'), 14.414901523597178),\n",
       " ((b'america', b'great'), 21.01215516254579),\n",
       " ((b'am', b'pleased'), 220.70361765682046),\n",
       " ((b'along', b'with'), 22.04256165473349),\n",
       " ((b'adam', b'schiff'), 675.7926829268293),\n",
       " ((b'about', b'me'), 11.045245343190548),\n",
       " ((b'able', b'to'), 10.59442063504708),\n",
       " ((b'a', b'lot'), 13.863832787481805),\n",
       " ((b'a', b'disgrace'), 10.586926855895197),\n",
       " ((b'900', b'pm'), 384.82638888888886),\n",
       " ((b'2020', b'election'), 16.792424242424243),\n",
       " ((b'2016', b'election'), 100.75454545454545),\n",
       " ((b'2', b'1/2'), 153.93055555555557),\n",
       " ((b'1/2', b'years'), 43.77172195892575)]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(list(bigram.phrasegrams.items()), reverse = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigram_tweets = list(bigram[tweets])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrain your model based on the new corpus containing bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6668007, 9777800)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bi_model = Word2Vec(sg = 0, cbow_mean = 1, size = 100, alpha = 0.025, min_alpha = 0.0001, \n",
    "                     window = 5, min_count = 5, sample = 0.001, negative = 5, workers = cpus - 1)\n",
    "bi_model.build_vocab(sentences = bigram_tweets, update = False, progress_per = 10000)\n",
    "bi_model.train(sentences = bigram_tweets, total_examples = bi_model.corpus_count, epochs = 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select one of the bigrams and compute the cosine similarity with the sum of the corresponding vectors from the unigram model  \n",
    "(e.g. $similarity[v_{united\\_states}, (v_{united} + v_{states})]$)  \n",
    "\n",
    "Should we expect a high or a low similarity?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.18019650461807343"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "unigrams = w2v_model.wv[\"united\"] + w2v_model.wv[\"states\"]\n",
    "bigram = bi_model.wv[\"united_states\"]\n",
    "\n",
    "sum(bigram * unigrams) / (math.sqrt(sum(bigram**2)) * math.sqrt(sum(unigrams**2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explore the embeddings for the bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('us', 0.535220742225647), ('importance', 0.37955600023269653), ('increase', 0.37705570459365845), ('usa', 0.3671112656593323), ('venezuelan', 0.35408592224121094), ('venezuela', 0.35022133588790894), ('chinese', 0.32250237464904785), ('republican_party', 0.32117512822151184), ('mexico', 0.31740838289260864), ('billions_of', 0.31637147068977356)]\n",
      "[('unhappy', 0.5052096247673035), ('no_collusion', 0.4682365953922272), ('mueller', 0.4426061809062958), ('no_obstruction', 0.4348973333835602), ('fact_that', 0.43326354026794434), ('obstruction', 0.43227651715278625), ('dossier', 0.42278459668159485), ('russian', 0.4212345480918884), ('robert_mueller', 0.409782350063324), ('ig', 0.396261602640152)]\n",
      "[('dan_bishop', 0.6345086097717285), ('nc03', 0.6164795160293579), ('murphy', 0.6152015924453735), ('greg', 0.5877571105957031), ('pennsylvania', 0.54262775182724), ('wisconsin', 0.5342702865600586), ('rally', 0.49785950779914856), ('tuesday', 0.49734747409820557), ('georgia', 0.49626803398132324), ('bay', 0.49287503957748413)]\n"
     ]
    }
   ],
   "source": [
    "print(bi_model.wv.most_similar(positive = [\"united_states\"]))\n",
    "print(bi_model.wv.most_similar(positive = [\"mueller_report\"]))\n",
    "print(bi_model.wv.most_similar(positive = [\"north_carolina\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optional task: Run the ``Phraser`` again, but this time on the corpus which already contains the bigrams.\n",
    "### This allows the model to build meaningful trigrams, like e.g. _\"new_\\__york_\\__times\"_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "phrases_tri = Phrases(bigram_tweets, min_count=20, threshold=10)\n",
    "trigram = Phraser(phrases_tri)\n",
    "\n",
    "sorted(list(trigram.phrasegrams.items()), reverse = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "trigram_tweets = list(trigram[tweets])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
