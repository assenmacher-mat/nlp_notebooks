{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word2Vec - Exercise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Necessary imports\n",
    "\n",
    "In order to handle the data properly we have to import the data and the modules we need:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# modules\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import nltk\n",
    "import gensim.models.word2vec as w2v"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, you need to download the data set \"tweets.csv\" from the GitHub repository https://github.com/assenmacher-mat/nlp_notebooks.  \n",
    "After running the next chunk, choose it in the upload window and in it will be available on colab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'google.colab'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-21dc3c638f66>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mfiles\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0muploaded\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfiles\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'google.colab'"
     ]
    }
   ],
   "source": [
    "from google.colab import files\n",
    "uploaded = files.upload()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import the data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_data = pd.read_csv(\"trump.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Next, just have a look at the data set in order to see which variables it contains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>text</th>\n",
       "      <th>created_at</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>favorite_count</th>\n",
       "      <th>is_retweet</th>\n",
       "      <th>id_str</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>At the request of @SenThomTillis I have declar...</td>\n",
       "      <td>10-04-2019 21:59:44</td>\n",
       "      <td>8562</td>\n",
       "      <td>36356</td>\n",
       "      <td>False</td>\n",
       "      <td>1180241114403610626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>Under my Administration Medicare Advantage pre...</td>\n",
       "      <td>10-04-2019 21:57:17</td>\n",
       "      <td>15248</td>\n",
       "      <td>54729</td>\n",
       "      <td>False</td>\n",
       "      <td>1180240498478534658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>WOW this is big stuff! https://t.co/H12yxMfua3</td>\n",
       "      <td>10-04-2019 19:46:59</td>\n",
       "      <td>15655</td>\n",
       "      <td>50526</td>\n",
       "      <td>False</td>\n",
       "      <td>1180207709985165313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>“I think it’s outrages that a Whistleblower is...</td>\n",
       "      <td>10-04-2019 14:12:23</td>\n",
       "      <td>19441</td>\n",
       "      <td>73966</td>\n",
       "      <td>False</td>\n",
       "      <td>1180123504924151809</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               source                                               text  \\\n",
       "0  Twitter for iPhone  At the request of @SenThomTillis I have declar...   \n",
       "1  Twitter for iPhone  Under my Administration Medicare Advantage pre...   \n",
       "2  Twitter for iPhone     WOW this is big stuff! https://t.co/H12yxMfua3   \n",
       "3  Twitter for iPhone  “I think it’s outrages that a Whistleblower is...   \n",
       "\n",
       "            created_at  retweet_count  favorite_count  is_retweet  \\\n",
       "0  10-04-2019 21:59:44           8562           36356       False   \n",
       "1  10-04-2019 21:57:17          15248           54729       False   \n",
       "2  10-04-2019 19:46:59          15655           50526       False   \n",
       "3  10-04-2019 14:12:23          19441           73966       False   \n",
       "\n",
       "                id_str  \n",
       "0  1180241114403610626  \n",
       "1  1180240498478534658  \n",
       "2  1180207709985165313  \n",
       "3  1180123504924151809  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet_data.loc[:3,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract the tweets to a list of tokenized texts:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_raw = [nltk.word_tokenize(tweet) for tweet in list(tweet_data.text)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display one exemplary tweet:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Under', 'my', 'Administration', 'Medicare', 'Advantage', 'premiums', 'next', 'year', 'will', 'be', 'their', 'lowest', 'in', 'the', 'last', '13', 'years', '.', 'We', 'are', 'providing', 'GREAT', 'healthcare', 'to', 'our', 'Seniors', '.', 'We', 'can', 'not', 'let', 'the', 'radical', 'socialists', 'take', 'that', 'away', 'through', 'Medicare', 'for', 'All', '!']\n"
     ]
    }
   ],
   "source": [
    "print(tweets_raw[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform all necessary preprocessing steps before we continue:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['under', 'my', 'administration', 'medicare', 'advantage', 'premiums', 'next', 'year', 'will', 'be', 'their', 'lowest', 'in', 'the', 'last', '13', 'years', '.', 'we', 'are', 'providing', 'great', 'healthcare', 'to', 'our', 'seniors', '.', 'we', 'can', 'not', 'let', 'the', 'radical', 'socialists', 'take', 'that', 'away', 'through', 'medicare', 'for', 'all', '!']\n"
     ]
    }
   ],
   "source": [
    "print([word.lower() for word in tweets_raw[1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "under my administration medicare advantage premiums next year will be their lowest in the last 13 years . we are providing great healthcare to our seniors . we can not let the radical socialists take that away through medicare for all !\n"
     ]
    }
   ],
   "source": [
    "print(\" \".join(tweets_raw[1]).lower())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
